{"cells":[{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+--------+----+----+----+----+----+--------+---------+---------+-----+\n","| station_id|    date|PRCP|SNOW|SNWD|TMAX|TMIN|Latitude|Longitude|Elevation|State|\n","+-----------+--------+----+----+----+----+----+--------+---------+---------+-----+\n","|CA001010235|19730707|null|null| 0.0| 0.0|null|    48.4|-123.4833|     17.0|   BC|\n","|CA001010235|19780330|14.0| 8.0| 0.0| 0.0|null|    48.4|-123.4833|     17.0|   BC|\n","|CA001010595|19690607|null|null| 0.0| 0.0|null| 48.5833|-123.5167|     85.0|   BC|\n","|CA001010720|19670815|28.9|12.8| 0.0| 0.0|null|    48.5|   -124.0|    351.0|   BC|\n","|CA001010960|19910618|null|null| 0.0| 0.0| 0.0|    48.6|-123.4667|     38.0|   BC|\n","|CA001010960|19960115|null|null|10.1| 0.0| 0.0|    48.6|-123.4667|     38.0|   BC|\n","|CA001010961|19751130|null|null|10.9|15.0|null| 48.5667|  -123.45|     31.0|   BC|\n","|CA001011467|19750419|null|null| 0.5| 0.0|null| 48.5833|-123.4167|     53.0|   BC|\n","|CA001011467|19870719|null|null| 0.0| 0.0| 0.0| 48.5833|-123.4167|     53.0|   BC|\n","|CA001011467|19890519|null|null| 0.0| 0.0| 0.0| 48.5833|-123.4167|     53.0|   BC|\n","+-----------+--------+----+----+----+----+----+--------+---------+---------+-----+\n","only showing top 10 rows\n","\n","None\n"]}],"source":["from pyspark.sql import SparkSession, functions, types\n","from pyspark.sql.functions import col,isnan,when,count\n","\n","def main():\n","\n","    stations_schema = types.StructType([\n","        types.StructField(\"Station ID\", types.StringType()),\n","        types.StructField(\"Latitude\", types.FloatType()),\n","        types.StructField(\"Longitude\", types.FloatType()),\n","        types.StructField(\"Elevation\", types.FloatType()),\n","        types.StructField(\"State\", types.StringType())\n","    ])\n","\n","    weather_schema = types.StructType([\n","        types.StructField('station_id', types.StringType()),\n","        types.StructField('date', types.StringType()),\n","        types.StructField('PRCP', types.FloatType()),\n","        types.StructField('SNOW', types.FloatType()),\n","        types.StructField('SNWD', types.FloatType()),\n","        types.StructField('TMAX', types.FloatType()),\n","        types.StructField('TMIN', types.FloatType())\n","    ])\n","    stations = spark.read.format('csv').schema(stations_schema).load(\"gs://big-data-1-project-storage/onlyBCStationNames\")\n","    stations = stations.withColumnRenamed('Station ID','station_id')\n","    weather = spark.read.format('csv').schema(weather_schema)\\\n","    .load(\"gs://big-data-1-project-storage/cleaned-data/weather_cleaned_1958Onwards.csv\")\n","#     print(type(weather))\n","#     print(type(stations))\n","#     print(weather.show(5))\n","#     print(stations.show(5))\n","    data = weather.join(functions.broadcast(stations), on=['station_id'], how='left')\n","#     print(type(data)) \n","    data = data.filter(data.station_id != \"null\")\n","    data = data.filter(data.date != \"null\")\n","    print(data.show(10))\n","\n","    data.write.save(\"gs://big-data-1-project-storage/cleaned-data/weather_stations.csv\", format='csv',header=True)\n","\n","\n","if __name__ == '__main__':\n","    spark = SparkSession.builder.appName('weather and station join').getOrCreate()\n","    spark.sparkContext.setLogLevel('WARN')\n","    sc = spark.sparkContext\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}