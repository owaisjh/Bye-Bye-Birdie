{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession, functions, types\n","from pyspark.sql.functions import col,isnan,when,count, radians, asin, sin, sqrt, cos,min,year,max\n","from pyspark.sql import Window as W\n","import uuid\n","\n","spark = SparkSession.builder.appName('weather_ebird_etl').getOrCreate()\n","spark.sparkContext.setLogLevel('WARN')\n","sc = spark.sparkContext\n","\n","weather_schema = types.StructType([\n","        types.StructField('station_id', types.StringType()),\n","        types.StructField('date', types.StringType()),\n","        types.StructField('PRCP', types.FloatType()),\n","        types.StructField('SNOW', types.FloatType()),\n","        types.StructField('SNWD', types.FloatType()),\n","        types.StructField('TMAX', types.FloatType()),\n","        types.StructField('TMIN', types.FloatType()),\n","        types.StructField(\"Latitude\", types.FloatType()),\n","        types.StructField(\"Longitude\", types.FloatType()),\n","        types.StructField(\"Elevation\", types.FloatType()),\n","        types.StructField(\"State\", types.StringType())\n","])\n","\n","ebird_schema = types.StructType([\n","        types.StructField(\"speciesCode\",types.StringType()),\n","        types.StructField(\"comName\",types.StringType()),\n","        types.StructField(\"sciName\",types.StringType()),\n","        types.StructField(\"locId\",types.StringType()),\n","        types.StructField(\"locName\",types.StringType()),\n","        types.StructField(\"obsDt\",types.DateType()),\n","        types.StructField(\"howMany\",types.StringType()),\n","        types.StructField(\"lat\",types.FloatType()),\n","        types.StructField(\"lng\",types.FloatType()),\n","        types.StructField(\"obsValid\",types.StringType()),\n","        types.StructField(\"obsReviewed\",types.StringType()),\n","        types.StructField(\"locationPrivate\",types.StringType()),\n","        types.StructField(\"subId\",types.StringType()),\n","    ])\n","\n","ebird = spark.read.format('csv').schema(ebird_schema).load(\"gs://big-data-1-project-storage/cleaned-data/ebird_nonull.csv\")\n","weather = spark.read.format('csv').schema(weather_schema).load(\"gs://big-data-1-project-storage/cleaned-data/weather_stations.csv\")\n","\n","weather = weather.filter(weather['station_id'] != 'null')\n","weather = weather.filter(weather['state'] == 'BC')\n","weather = weather.filter( (weather['TMAX'].isNotNull())  & (weather['TMIN'].isNotNull()) )\n","\n","weather = weather.withColumn(\"year\", functions.substring(weather['date'], 0,4))\\\n","    .withColumn('month', functions.substring(weather['date'], 5,2))\\\n","    .withColumn('day', functions.substring(weather['date'], 7,2))\n","\n","weather = weather.withColumn(\"date_final\", functions.concat_ws(\"-\",functions.col(\"year\"),functions.col(\"month\"),functions.col(\"day\")).cast(\"date\"))\n","\n","weather = weather.drop('year','month','day')\n","\n","ebird = ebird.filter( (ebird['lat'].isNotNull())  & (ebird['lng'].isNotNull()) )\n","\n","\n","ebird = ebird.withColumn(\"ebird_id\", functions.expr(\"uuid()\"))\n","\n","savingEbird = ebird\n","savingWeather = weather\n","\n","# savingEbird and saving Weather is saved here \n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["start = 1959\n","end = 2021 "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1963\n","1964\n","1965\n"]}],"source":["# yr = 1959\n","for yr in range(start,end+1):\n","    ebird_1959 = savingEbird.filter(year(\"ObsDt\")==yr)\n","    weather_1959 = savingWeather.filter(year(\"date_final\")==yr)\n","\n","#     ebird_1959.count()\n","\n","\n","    join_1959 = ebird_1959.crossJoin(weather_1959).withColumn(\"dist_longit\", radians(weather_1959[\"Longitude\"]) - radians(ebird_1959[\"lng\"])).withColumn(\"dist_latit\", radians(weather_1959[\"Latitude\"]) - radians(ebird_1959[\"lat\"]))\n","\n","    join_1959 = join_1959.withColumn(\"haversine_distance_kms\", asin(sqrt(\n","                                             sin(join_1959[\"dist_latit\"] / 2) ** 2 + cos(radians(join_1959[\"lat\"]))\n","                                             * cos(radians(join_1959[\"Latitude\"])) * sin(join_1959[\"dist_longit\"] / 2) ** 2\n","                                             )\n","                                        ) * 2 * 6371).drop(\"dist_longit\",\"dist_latit\",\n","                                                          \"obsValid\",\"obsReviewed\",\n","                                                          \"locationPrivate\",\"subId\")\n","\n","\n","    join_1959= join_1959.filter(join_1959['obsDt'] == join_1959['date_final'])\n","\n","    min_dist_1959 = join_1959.groupBy(['ebird_id']).agg({'haversine_distance_kms':'min'}).withColumnRenamed('min(haversine_distance_kms)','min_dist')\n","\n","\n","    min_dist_1959 = min_dist_1959.withColumnRenamed('ebird_id','ebird_id_min')\n","\n","    condition = [min_dist_1959['ebird_id_min'] == join_1959['ebird_id'] , min_dist_1959['min_dist'] ==join_1959['haversine_distance_kms'] ] \n","\n","    join_1959 = join_1959.join(min_dist_1959, condition, 'inner')\n","    print(yr)\n","#     join_1959.count()\n","\n","    join_1959= join_1959.drop('ebird_id_min','haversine_distance_kms' ) \n","    join_1959.write.save(\"gs://big-data-1-project-storage/cleaned-data/joined-data-final/\"+str(yr), format='csv',header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#combining all the multiple year files to one \n","inputs = \"gs://big-data-1-project-storage/cleaned-data/joined-data-final\"\n","\n","\n","schema = types.StructType([\n","            types.StructField(\"speciesCode\",types.StringType()),\n","            types.StructField(\"comName\",types.StringType()),\n","            types.StructField(\"sciName\",types.StringType()),\n","            types.StructField(\"locId\",types.StringType()),\n","            types.StructField(\"locName\",types.StringType()),\n","            types.StructField(\"obsDt\",types.DateType()),\n","            types.StructField(\"howMany\",types.StringType()),\n","            types.StructField(\"lat\",types.FloatType()),\n","            types.StructField(\"lng\",types.FloatType()),\n","            types.StructField(\"ebird_id\",types.StringType()),\n","\n","            types.StructField('station_id', types.StringType()),\n","            types.StructField('date', types.StringType()),\n","            types.StructField('PRCP', types.FloatType()),\n","            types.StructField('SNOW', types.FloatType()),\n","            types.StructField('SNWD', types.FloatType()),\n","            types.StructField('TMAX', types.FloatType()),\n","            types.StructField('TMIN', types.FloatType()),\n","            types.StructField(\"Latitude\", types.FloatType()),\n","            types.StructField(\"Longitude\", types.FloatType()),\n","            types.StructField(\"Elevation\", types.FloatType()),\n","            types.StructField(\"State\", types.StringType()),\n","            types.StructField(\"date_final\",types.DateType()),\n","            types.StructField(\"min_dist\", types.FloatType()),\n","\n","     \n","           \n","        ])\n","\n","\n","\n","\n","finalsaver = spark.read.format('csv').option(\"recursiveFileLookup\",\"true\").schema(schema).load(inputs)\n","\n","\n","finalsaver = finalsaver.filter( finalsaver['lat'].isNotNull() )\n","\n","filename.write.save(\"gs://big-data-1-project-storage/cleaned-data/joined-data-final-final\", format='csv',header=True)\n","\n","print(finalsaver.show(3))\n","print(finalsaver.count())\n"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}